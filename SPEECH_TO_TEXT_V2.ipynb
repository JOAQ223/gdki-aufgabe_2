{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JOAQ223/gdki-aufgabe_2/blob/main/SPEECH_TO_TEXT_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH0xOZ4qkOjy"
      },
      "source": [
        "1. JIWER Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyoNFgsid3BQ",
        "outputId": "352b84fb-96d7-401a-911c-ed8224cf13be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-2.5.1-py3-none-any.whl (15 kB)\n",
            "Collecting levenshtein==0.20.2\n",
            "  Downloading Levenshtein-0.20.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, levenshtein, jiwer\n",
            "Successfully installed jiwer-2.5.1 levenshtein-0.20.2 rapidfuzz-2.13.7\n"
          ]
        }
      ],
      "source": [
        "pip install jiwer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vd0Cqw8kXFO"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rt37fdokFnx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from jiwer import wer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QouuaXDqnKb1"
      },
      "source": [
        "**Import LJSpeech Dataset**\n",
        "* ID: Name of the corresponding wav file\n",
        "* Transcription: words spoken by the reader (UTF-8)\n",
        "* Normalized Transcription: transcription with numbers, ordinals, and monetary units expanded into full words (UTF-8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hUDsqG5n-tL"
      },
      "source": [
        "# https://keithito.com/LJ-Speech-Dataset/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWkiagJYnezu"
      },
      "source": [
        "# https://www.kaggle.com/datasets/showmik50/ljspeech-sr16k-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8AwHfwRngfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037d5304-878c-424f-edc5-5f77c08bbc4e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "2748572632/2748572632 [==============================] - 238s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Heruanterladen von Dataset \n",
        "data_url = \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\"\n",
        "data_path = keras.utils.get_file(\"LJSpeech-1.1\", data_url, untar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWsWEEi3p20_"
      },
      "outputs": [],
      "source": [
        "#Alle Datein speicher in  wavs files\n",
        "wav_path = data_path + \"/wavs/\"\n",
        "\n",
        "#Speicher mit extension  \n",
        "metadata_path = data_path + \"/metadata.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q46Qsp7gqXEh"
      },
      "outputs": [],
      "source": [
        "#read the metadata file and parse it\n",
        "metadata_df = pd.read_csv(metadata_path, sep=\"|\", header=None, quoting=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id0WjmkCqz8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "822ee619-095a-4542-c3d2-51e3af904255"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0                                                  1  \\\n",
              "0  LJ001-0001  Printing, in the only sense with which we are ...   \n",
              "1  LJ001-0002                     in being comparatively modern.   \n",
              "2  LJ001-0003  For although the Chinese took impressions from...   \n",
              "3  LJ001-0004  produced the block books, which were the immed...   \n",
              "4  LJ001-0005  the invention of movable metal letters in the ...   \n",
              "5  LJ001-0006  And it is worth mention in passing that, as an...   \n",
              "6  LJ001-0007  the earliest book printed with movable types, ...   \n",
              "7  LJ001-0008                          has never been surpassed.   \n",
              "8  LJ001-0009  Printing, then, for our purpose, may be consid...   \n",
              "9  LJ001-0010  Now, as all books not primarily intended as pi...   \n",
              "\n",
              "                                                   2  \n",
              "0  Printing, in the only sense with which we are ...  \n",
              "1                     in being comparatively modern.  \n",
              "2  For although the Chinese took impressions from...  \n",
              "3  produced the block books, which were the immed...  \n",
              "4  the invention of movable metal letters in the ...  \n",
              "5  And it is worth mention in passing that, as an...  \n",
              "6  the earliest book printed with movable types, ...  \n",
              "7                          has never been surpassed.  \n",
              "8  Printing, then, for our purpose, may be consid...  \n",
              "9  Now, as all books not primarily intended as pi...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee5d397b-919f-4d4c-85b9-aedae3ea5968\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LJ001-0001</td>\n",
              "      <td>Printing, in the only sense with which we are ...</td>\n",
              "      <td>Printing, in the only sense with which we are ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LJ001-0002</td>\n",
              "      <td>in being comparatively modern.</td>\n",
              "      <td>in being comparatively modern.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LJ001-0003</td>\n",
              "      <td>For although the Chinese took impressions from...</td>\n",
              "      <td>For although the Chinese took impressions from...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LJ001-0004</td>\n",
              "      <td>produced the block books, which were the immed...</td>\n",
              "      <td>produced the block books, which were the immed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LJ001-0005</td>\n",
              "      <td>the invention of movable metal letters in the ...</td>\n",
              "      <td>the invention of movable metal letters in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LJ001-0006</td>\n",
              "      <td>And it is worth mention in passing that, as an...</td>\n",
              "      <td>And it is worth mention in passing that, as an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LJ001-0007</td>\n",
              "      <td>the earliest book printed with movable types, ...</td>\n",
              "      <td>the earliest book printed with movable types, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LJ001-0008</td>\n",
              "      <td>has never been surpassed.</td>\n",
              "      <td>has never been surpassed.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LJ001-0009</td>\n",
              "      <td>Printing, then, for our purpose, may be consid...</td>\n",
              "      <td>Printing, then, for our purpose, may be consid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LJ001-0010</td>\n",
              "      <td>Now, as all books not primarily intended as pi...</td>\n",
              "      <td>Now, as all books not primarily intended as pi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee5d397b-919f-4d4c-85b9-aedae3ea5968')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee5d397b-919f-4d4c-85b9-aedae3ea5968 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee5d397b-919f-4d4c-85b9-aedae3ea5968');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "metadata_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRMD0xU1_9S8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d108165-3de1-4662-9277-3ddb24a44ee4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    file_name                           normalized_transcription\n",
              "0  LJ012-0170  According to his statement, when sentenced to ...\n",
              "1  LJ043-0152  She said that she kept the note to use against...\n",
              "2  LJ034-0149  Brennan appeared to revert to his earlier inab..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52f315b2-b75d-4cf6-b214-f04e0791d8a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>normalized_transcription</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LJ012-0170</td>\n",
              "      <td>According to his statement, when sentenced to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LJ043-0152</td>\n",
              "      <td>She said that she kept the note to use against...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LJ034-0149</td>\n",
              "      <td>Brennan appeared to revert to his earlier inab...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52f315b2-b75d-4cf6-b214-f04e0791d8a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52f315b2-b75d-4cf6-b214-f04e0791d8a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52f315b2-b75d-4cf6-b214-f04e0791d8a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# We need to have the transcription and the real text to  train our model with the correct ouptu from the audiofiles \n",
        "\n",
        "metadata_df.columns = [\"file_name\", \"transcription\", \"normalized_transcription\"]\n",
        "metadata_df = metadata_df[[\"file_name\", \"normalized_transcription\"]]\n",
        "metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n",
        "metadata_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4dRNNMiEEFb"
      },
      "source": [
        "Split the data into training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TudybWJfAh96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be783291-829c-4a80-a482-4ce303dd0fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the training set: 11790\n",
            "Size of the validation set: 1310\n"
          ]
        }
      ],
      "source": [
        "#split1=int(len(metadata_df) * 0.30)\n",
        "# 90% for training, the rest of 10% for validation\n",
        "split = int(len(metadata_df) * 0.90)\n",
        "df_train = metadata_df[:split]\n",
        "df_val = metadata_df[split:]\n",
        "\n",
        "print(f\"Size of the training set: {len(df_train)}\")\n",
        "print(f\"Size of the validation set: {len(df_val)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRHID03zHmst"
      },
      "source": [
        "# Prepocessing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZCH7CDMHqQm"
      },
      "source": [
        "We first prepare the vocabulary to be used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Odq0YkIHf6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a79bc7-f328-40ed-f5cd-ef4be7485507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', ' '] (size =31)\n"
          ]
        }
      ],
      "source": [
        "# The set of characters accepted in the transcription.\n",
        "characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"]\n",
        "# Mapping characters to integers\n",
        "char_to_num = keras.layers.StringLookup(vocabulary=characters, oov_token=\"\")\n",
        "# Mapping integers back to original characters \n",
        "num_to_char = keras.layers.StringLookup( vocabulary=char_to_num.get_vocabulary(), oov_token =\"\", invert=True)\n",
        "\n",
        "print(\n",
        "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
        "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoPqsFZ1XkUe"
      },
      "source": [
        "We create now a function that describes the transformation that we apply to each element of our dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEFrPS6tHxf0"
      },
      "outputs": [],
      "source": [
        "char_to_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNRYvKH9XqNp"
      },
      "outputs": [],
      "source": [
        "# An integer scalar Tensor. The window length in samples\n",
        "frame_length = 256\n",
        "# An integer scalar Tensor. The number of samples to step.\n",
        "frame_step = 160\n",
        "# An integer scalar Tensor. The size of the FFT to apply.\n",
        "# If not provided, uses the smallest power of 2 enclosing frame_length.\n",
        "fft_length = 384\n",
        "\n",
        "def encode_single_sample(wav_file, label):\n",
        "  #############################################\n",
        "  ## Process the Audio\n",
        "  #############################################\n",
        "  # 1. Read wav file\n",
        "  file = tf.io.read_file(wav_path + wav_file + \".wav\")\n",
        "  # 2. Decode the wav file , decode a 16-bit PCM WAV file to a float tensor\n",
        "  audio, _ = tf.audio.decode_wav(file)\n",
        "  # remove 1 dimensional tensor \n",
        "  audio = tf.squeeze(audio, axis=-1)\n",
        "  # 3. Change type to float\n",
        "  audio = tf.cast(audio, tf.float32)\n",
        "  # 4. Get the spectrogram for Model trainign the fequenz  here for a  frequenz number to a letter)\n",
        "  spectrogram = tf.signal.stft(audio, frame_length=frame_length,  frame_step=frame_step, fft_length=fft_length)\n",
        "  # 5. We only need the magnitude, which can be derived by applying tf.abs\n",
        "  spectrogram = tf.abs(spectrogram)\n",
        "  spectrogram = tf.math.pow(spectrogram, 0.5)\n",
        "  # 6. Normalisation\n",
        "  means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
        "  stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
        "  spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
        "  #############################################\n",
        "  ## Process the Label\n",
        "  #############################################\n",
        "  # 7. Convert label to Lower case\n",
        "  label = tf.strings.lower(label)\n",
        "  # 8. Split the label\n",
        "  label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n",
        "  # 9. Map the characters in label to numbers, sounds , frequenz to number \n",
        "  label = char_to_num(label)\n",
        "  # 10. Return a dict as our model is expecting two inputs\n",
        "  \n",
        "  return spectrogram, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIUYQ1WjOPxd"
      },
      "source": [
        "Creating Dataset Objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUiJCsB9OaGT"
      },
      "source": [
        "We create a tf.data.Dataset object that yields the transformed elements, in the same order as they appeared in the input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w56Hdpt-OOxU"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "# Define the training dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(df_train[\"file_name\"]), list(df_train[\"normalized_transcription\"]))\n",
        ")\n",
        "train_dataset = (\n",
        "    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "#Define the validation dataset\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(df_val[\"file_name\"]), list(df_val[\"normalized_transcription\"]))\n",
        ")\n",
        "validation_dataset = (\n",
        "     validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V4n-Cl6Rj9Q"
      },
      "source": [
        "Visualize the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGsdBOUnRqxp"
      },
      "source": [
        "Let's visualize an example in our dataset, including the audio clip, the spectogram and the corresponding label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYqi53NKPvan"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8, 5))\n",
        "for batch in train_dataset.take(1):\n",
        "  spectrogram = batch[0][0].numpy()\n",
        "  spectrogram = np.array([np.trim_zeros(x) for x in np.transpose(spectrogram)])\n",
        "  label = batch[1][0]\n",
        "  # Spectrogram\n",
        "  label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"UTF-8\")\n",
        "  ax = plt.subplot(2, 1, 1)\n",
        "  ax.imshow(spectrogram, vmax=1)\n",
        "  ax.set_title(label)\n",
        "  ax.axis(\"off\")\n",
        "  # Wav\n",
        "  file = tf.io.read_file(wav_path + list(df_train[\"file_name\"])[0] + \".wav\")\n",
        "  audio, _ = tf.audio.decode_wav(file)\n",
        "  audio = audio.numpy()\n",
        "  ax = plt.subplot(2, 1, 2)\n",
        "  plt.plot(audio)\n",
        "  ax.set_title(\"Signal Wave\")\n",
        "  ax.set_xlim(0, len(audio))\n",
        "  display.display(display.Audio(np.transpose(audio), rate=16000))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFTcMvlTUONH"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glmwzXV2URm2"
      },
      "source": [
        "We first define the CTC Loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIobnkRJTTnf"
      },
      "outputs": [],
      "source": [
        "def CTCLoss(y_true, y_pred):\n",
        "  # Compute the training-time loss value\n",
        "  batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "  input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "  label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "  input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "  label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "  loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyAdIAFrVVfP"
      },
      "source": [
        "We now define our model. We will define a model similar to DeepSpeech2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cs7T3IpVh3a"
      },
      "outputs": [],
      "source": [
        "def build_model(input_dim, output_dim, rnn_layers=5, rnn_units=128):\n",
        "    \"\"\"Model similar to DeepSpeech2.\"\"\"\n",
        "    # Model's input\n",
        "    input_spectrogram = layers.Input((None, input_dim), name=\"input\")\n",
        "    # Expand the dimension to use 2D CNN.\n",
        "    x = layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectrogram)\n",
        "    # Convolution layer 1\n",
        "    x = layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=[11, 41],\n",
        "        strides=[2, 2],\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"conv_1\",\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n",
        "    x = layers.ReLU(name=\"conv_1_relu\")(x)\n",
        "    # Convolution layer 2\n",
        "    x = layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=[11, 21],\n",
        "        strides=[1, 2],\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"conv_2\",\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n",
        "    x = layers.ReLU(name=\"conv_2_relu\")(x)\n",
        "    # Reshape the resulted volume to feed the RNNs layers\n",
        "    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)\n",
        "    # RNN layers\n",
        "    for i in range(1, rnn_layers + 1):\n",
        "        recurrent = layers.GRU(\n",
        "            units=rnn_units,\n",
        "            activation=\"tanh\",\n",
        "            recurrent_activation=\"sigmoid\",\n",
        "            use_bias=True,\n",
        "            return_sequences=True,\n",
        "            reset_after=True,\n",
        "            name=f\"gru_{i}\",\n",
        "        )\n",
        "        x = layers.Bidirectional(\n",
        "            recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\"\n",
        "        )(x)\n",
        "        if i < rnn_layers:\n",
        "            x = layers.Dropout(rate=0.5)(x)\n",
        "    # Dense layer\n",
        "    x = layers.Dense(units=rnn_units * 2, name=\"dense_1\")(x)\n",
        "    x = layers.ReLU(name=\"dense_1_relu\")(x)\n",
        "    x = layers.Dropout(rate=0.5)(x)\n",
        "    # Classification layer\n",
        "    output = layers.Dense(units=output_dim + 1, activation=\"softmax\")(x)\n",
        "    # Model\n",
        "    model = keras.Model(input_spectrogram, output, name=\"DeepSpeech_2\")\n",
        "    # Optimizer\n",
        "    opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    # Compile the model and return\n",
        "    model.compile(optimizer=opt, loss=CTCLoss)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Get the model\n",
        "model = build_model(\n",
        "    input_dim=fft_length // 2 + 1,\n",
        "    output_dim=char_to_num.vocabulary_size(),\n",
        "    rnn_units=512,\n",
        ")\n",
        "model.summary(line_length=110)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGBU9jWRhtCe"
      },
      "source": [
        "Training and Evaluating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEfs_7NdhHkB"
      },
      "outputs": [],
      "source": [
        "# A utility function to decode the output of the network\n",
        "def decode_batch_predictions(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for result in results:\n",
        "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(result)\n",
        "    return output_text\n",
        "\n",
        "\n",
        "# A callback class to output a few transcriptions during training\n",
        "class CallbackEval(keras.callbacks.Callback):\n",
        "    \"\"\"Displays a batch of outputs after every epoch.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def on_epoch_end(self, epoch: int, logs=None):\n",
        "        predictions = []\n",
        "        targets = []\n",
        "        for batch in self.dataset:\n",
        "            X, y = batch\n",
        "            batch_predictions = model.predict(X)\n",
        "            batch_predictions = decode_batch_predictions(batch_predictions)\n",
        "            predictions.extend(batch_predictions)\n",
        "            for label in y:\n",
        "                label = (\n",
        "                    tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "                )\n",
        "                targets.append(label)\n",
        "        wer_score = wer(targets, predictions)\n",
        "        print(\"-\" * 100)\n",
        "        print(f\"Word Error Rate: {wer_score:.4f}\")\n",
        "        print(\"-\" * 100)\n",
        "        for i in np.random.randint(0, len(predictions), 2):\n",
        "            print(f\"Target    : {targets[i]}\")\n",
        "            print(f\"Prediction: {predictions[i]}\")\n",
        "            print(\"-\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtfRb3-fh-9I"
      },
      "source": [
        "Let's the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnR1oWQ6h8Sw"
      },
      "outputs": [],
      "source": [
        "# Define the number of epochs.\n",
        "epochs = 50\n",
        "# Callback function to check transcription on the val set.\n",
        "validation_callback = CallbackEval(validation_dataset)\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=epochs,\n",
        "    callbacks=[validation_callback],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiakkFPpiSzY"
      },
      "source": [
        "Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gptq7Z1ieRV"
      },
      "source": [
        "# Conclusion\n",
        "In practice, you should train  between 50 to 100 epochs or more. Each epoch takes approximately 5-6mn using a GeForce RTX 2080 Ti GPU. The model we trained at 50 epochs has a Word Error Rate (WER) ≈ 16% to 17%.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5jpsPZXiJUl"
      },
      "outputs": [],
      "source": [
        "# Let's check results on more validation samples\n",
        "predictions = []\n",
        "targets = []\n",
        "for batch in validation_dataset:\n",
        "    X, y = batch\n",
        "    batch_predictions = model.predict(X)\n",
        "    batch_predictions = decode_batch_predictions(batch_predictions)\n",
        "    predictions.extend(batch_predictions)\n",
        "    for label in y:\n",
        "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"UTF-8\")\n",
        "        targets.append(label)\n",
        "wer_score = wer(targets, predictions)\n",
        "print(\"-\" * 100)\n",
        "print(f\"Word Error Rate: {wer_score:.4f}\")\n",
        "print(\"-\" * 100)\n",
        "for i in np.random.randint(0, len(predictions), 5):\n",
        "    print(f\"Target    : {targets[i]}\")\n",
        "    print(f\"Prediction: {predictions[i]}\")\n",
        "    print(\"-\" * 100)chr"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}